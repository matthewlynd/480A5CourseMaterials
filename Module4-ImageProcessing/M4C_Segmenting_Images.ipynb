{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrDdrqdrefmB"
      },
      "source": [
        "Introduction to Image Processing - Segmenting Images\n",
        "<html>\n",
        "    <summary></summary>\n",
        "         <div> <p></p> </div>\n",
        "         <div style=\"font-size: 20px; width: 800px;\"> \n",
        "              <h1>\n",
        "               <left>Basic Image Segmentation in Python</left>\n",
        "              </h1>\n",
        "              <p><left>============================================================================</left> </p>\n",
        "<pre>Course: BIOM 480A5, Spring 2025\n",
        "Instructor: Brian Munsky\n",
        "Authors: Dr. Zach Fox, Dr. Luis Aguilera, Brian Munsky\n",
        "Contact Info: munsky@colostate.edu\n",
        "</pre>\n",
        "         </div>\n",
        "    </p>\n",
        "\n",
        "</html>\n",
        "\n",
        "<details>\n",
        "  <summary>Copyright info</summary>\n",
        "\n",
        "```\n",
        "Copyright 2024 Brian Munsky\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "```\n",
        "<details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiskOfmuh3kB"
      },
      "source": [
        "# Abstract\n",
        "\n",
        "In this notebook, we will talk about single-cell segmentation and spot detection using Python. By now, we have covered basic image manipulation (see Module 4A and 4B). Here, our goal is introduce the basics of single-cell segmentation and particle detection.\n",
        "\n",
        "## Learning Objectives\n",
        "After completing this notebook, you should be able to:\n",
        "\n",
        "1. Explain the more common methods used to segment cells from microscope images.\n",
        "2. Explain what a ***segmentation mask is***.\n",
        "3. Explain and be able to execute basic segmentation methods based on **threshold selection**.\n",
        "4. Perform single-cell segmentation using modern **machine learning** based methods using CellPose\n",
        "5. Understand the basics of **particle detection**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Introduction to segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1GXNcnnA35h"
      },
      "source": [
        "![alt text](FigsA/Module_1_3/Slide2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of7qHN_AcckN"
      },
      "source": [
        "Main steps of (cell) segmenation and spot detection:\n",
        "\n",
        "1.   Thresholding\n",
        "2.   Binarization\n",
        "3.   Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myDW1oXaI6eQ"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLR44_1zI_EI"
      },
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide3.png alt=\"drawing\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NI7-7PeJGFX"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8MWhHDPngt"
      },
      "source": [
        "## Manual segmentation software\n",
        "Using software such as [ImageJ/FIJI](https://imagej.nih.gov/ij/), [Napari](https://napari.org) or even something like Microsoft Paint, one can manually outline cells. \n",
        "\n",
        "This can be cumbersome and impractical for processing thousands of cells over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTzoxtM5JQrU"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwOmK0TNuMNh"
      },
      "source": [
        "Check out this tool ([makesense](https://www.makesense.ai)) to create your own masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPtmi1A99Bj-"
      },
      "source": [
        "You can find some images in the following [link](https://www.dropbox.com/s/d9my4cp2j3ven04/test_data_uqbio2022.zip?dl=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yV1XbVUemLL"
      },
      "source": [
        "# 2. Segmentation using Thresholding approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvSjR9G263Lu"
      },
      "source": [
        "## 2.A. Watershed Methods\n",
        "The scikit-image library has an excellent tutorial on [watershed methods](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html). Popular tools that apply such methods to single cells are:\n",
        "* [CellStar](http://cellstar-algorithm.org) (Matlab, Python, CellProfiler PlugIn)\n",
        "* [FogBank](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-014-0431-x#additional-information) (Matlab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkxfpjV7JLk4"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install --upgrade  cellpose\n",
        "# os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "\n",
        "from cellpose import plot, models\n",
        "# Note -- your kernel may crash when running this cell. \n",
        "# If it does, just restart the kernel and run this cell again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4sEg4oNqF7m"
      },
      "outputs": [],
      "source": [
        "# Loading libraries\n",
        "import random                        # Library to generate random numbers\n",
        "import skimage                       # Library for image manipulation\n",
        "import numpy as np                   # Library for array manipulation\n",
        "import urllib.request                # Library to download data\n",
        "import matplotlib.pyplot as plt      # Library used for plotting\n",
        "from skimage import io, measure      # Module from skimage\n",
        "from skimage.io import imread        # Module from skimage to read images as numpy arrays\n",
        "from skimage.filters import gaussian # Module working with a gaussian filter\n",
        "import pathlib                              # Library to work with file paths\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "from ipywidgets import interactive, HBox, VBox, Layout\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from skimage.morphology import binary_dilation\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.draw import polygon\n",
        "from skimage.measure import regionprops\n",
        "from skimage.color import label2rgb\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.morphology import binary_erosion\n",
        "from skimage.morphology import binary_closing\n",
        "from skimage.morphology import binary_opening\n",
        "from skimage.morphology import disk\n",
        "from skimage.morphology import remove_small_objects\n",
        "from scipy import ndimage as ndi              # Distance Transform\n",
        "from skimage.feature import peak_local_max    # Local maxima in a matrix\n",
        "from skimage.segmentation import watershed    # Watershed algorithm\n",
        "from skimage.filters import difference_of_gaussians"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aomp36oZtG76"
      },
      "source": [
        "Let's get started by downloading a sample image of a cell and plotting it using `matplotlib`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLyKJMqKqQ4k"
      },
      "outputs": [],
      "source": [
        "# Downloading a test image\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209']\n",
        "print('Downloading file...')\n",
        "figName = './image_cell.tif'\n",
        "urllib.request.urlretrieve(urls[0], figName)\n",
        "# Loading figure to the notebook\n",
        "images = imread(figName)\n",
        "print('File is downloaded and accessible in: ... ./image_cell.tif ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDkStCTuxpND"
      },
      "outputs": [],
      "source": [
        "# How do we find the figure we just saved?  I.e., what is figName = './image_cell.tif'   \n",
        "# What is our current working directory (cwd)?    #import os #os.getcwd()\n",
        "print(f'Our cvw is : {os.getcwd()}')\n",
        "\n",
        "# What is the absolute path to the file?  #import os #os.path.abspath(figName)\n",
        "print(f'The absolute path to the file is : {os.path.abspath(figName)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIQDfN7SseSF"
      },
      "outputs": [],
      "source": [
        "# Printing the shape of the image\n",
        "print('Original image shape: ' , images.shape)  # [T,Y,X,C]\n",
        "\n",
        "# Selecting a frame and a color channel\n",
        "img = images[0,:,:,0]\n",
        "print('Single image shape: ' , img.shape)  # [Y,X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXYlGZuLyBDq"
      },
      "outputs": [],
      "source": [
        "# What is the difference  between \"images\" and \"img\" after the above code?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hUdKmu8sK-WO"
      },
      "outputs": [],
      "source": [
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, img.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(img,cmap='Reds_r') # Reds_r\n",
        "\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , img,  rstride=20, cstride=20, shade=False, cmap='Spectral')\n",
        "ax2.view_init(20, 45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4kyOnGit7TY"
      },
      "source": [
        "Recall when we plotted the histogram of the intensity pixels to get a sense of the distribution of pixel intensities throughout the image. Let's do that again here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIdRU5m7t5qI"
      },
      "outputs": [],
      "source": [
        "# Plotting the intensity distribution\n",
        "f, ax = plt.subplots()\n",
        "ax.hist(img.flatten(),color='orangered',bins=35)  # .ravel()\n",
        "ax.set_xlabel('Intensity')\n",
        "ax.set_ylabel('# of pixels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl7nsVhZypXQ"
      },
      "outputs": [],
      "source": [
        "# There are three peaks in the histogram. What do you think they represent?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YryL4pa6WbwY"
      },
      "source": [
        "## 2.B. Segmentaton based on threshold selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1z48XCyufes"
      },
      "source": [
        "Based on this image, we can guess a threshold of pixel intensities that are \"cells\" vs \"not cells\". What do you think would make a good threshold?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZNHIVJyuUu3"
      },
      "outputs": [],
      "source": [
        "# Thresholding the image\n",
        "def viewer(threshold=50):\n",
        "    mask_image = np.zeros(img.shape)\n",
        "    mask_image[img>threshold] = 255\n",
        "    f,ax = plt.subplots()\n",
        "    ax.imshow(mask_image, cmap='Greys')\n",
        "    plt.show()\n",
        "\n",
        "interactive_plot = interactive(viewer,threshold = widgets.IntSlider(min=0,max=2000,step=1,value=0,description='threshold'))       \n",
        "controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
        "output = interactive_plot.children[-1]\n",
        "\n",
        "# Display the controls and output as an interactive widget\n",
        "display(VBox([controls, output]))    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grjDaogdv3oK"
      },
      "source": [
        "This mask image is useful, especially considering we simply took all of the pixels with a value bigger than `threshold`.\n",
        "\n",
        "However, we know that the outside ought to be more smooth. Let's try applying a Gaussian filter to smooth out the mask image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzF6Y7hFJ0RY"
      },
      "outputs": [],
      "source": [
        "# Thresholding the image\n",
        "def viewer(threshold=50, sigma=5):\n",
        "    mask_image = np.zeros(img.shape)\n",
        "    mask_image[img>threshold] = 255\n",
        "    new_mask = gaussian(mask_image, sigma=sigma)\n",
        "    f,ax = plt.subplots(1,2, figsize=(10,5))\n",
        "    ax[0].imshow(mask_image, cmap='Spectral')\n",
        "    ax[1].imshow(new_mask, cmap='Spectral')\n",
        "    plt.show()\n",
        "    return new_mask\n",
        "\n",
        "interactive_plot = interactive(viewer, \\\n",
        "            threshold = widgets.IntSlider(min=0,max=2000,step=1,value=0,description='threshold'),\\\n",
        "            sigma = widgets.IntSlider(min=0,max=10,step=1,value=0,description='sigma'))       \n",
        "\n",
        "controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
        "output = interactive_plot.children[-1]\n",
        "\n",
        "# Display the controls and output as an interactive widget\n",
        "display(VBox([controls, output]))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umZNGAcpnyBc"
      },
      "outputs": [],
      "source": [
        "# Plotting all contours detected in the filtered image\n",
        "new_mask = interactive_plot.result\n",
        "\n",
        "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
        "contours = measure.find_contours(new_mask, level=125 ) # level is half of 255 (ish). What happens if we change it?\n",
        "contours_connected = np.vstack((contours))\n",
        "ax[0].imshow(new_mask, cmap='Greys')\n",
        "ax[1].imshow(images[0,:,:,0], cmap='Spectral')\n",
        "for contour in contours:\n",
        "  ax[0].plot(contour[:,1],contour[:,0],color='r')  \n",
        "  ax[1].plot(contour[:,1],contour[:,0],color='r')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsPgscPyTV2x"
      },
      "outputs": [],
      "source": [
        "# How would I learn how the function find_contours works?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYTvmKbHxNkO"
      },
      "source": [
        "So far so good. By setting `threshold=700` we were able to find the \"main\" cell in the image. But what happens when we want to get all three? Try lowering the threshold to  300 and running the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAAHGObey5df"
      },
      "source": [
        "_it looks like a crab_ !\n",
        "\n",
        "\n",
        "In the cell below, we will try to take the connected image below and use a [watershed algorithm](https://en.wikipedia.org/wiki/Watershed_(image_processing) to break it into 3 distinct cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfxyAEnNzCJM"
      },
      "outputs": [],
      "source": [
        "# make a new mask from the contours array\n",
        "watershed_starting_mask = np.zeros(img.shape).astype(int)                    # Prealocating an array with zeros. Notice the datatype.\n",
        "rr, cc = polygon(contours_connected[:,0], contours_connected[:,1])           # Returns the coordinates inside the contour\n",
        "watershed_starting_mask[rr,cc] = 1                                           # Replacing all values inside the contour with ones.\n",
        "\n",
        "# Plotting the mask\n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(watershed_starting_mask, cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "# Printing the minimum and maximum values in the image\n",
        "print('min value in mask: ', np.min(watershed_starting_mask) )\n",
        "print('max value in mask: ', np.max(watershed_starting_mask) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAaH0cmFfjJc"
      },
      "source": [
        "To find more information about the specific method use\n",
        "\n",
        "```\n",
        "help(watershed)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_wgirknvBzR"
      },
      "source": [
        "## 2.C. Distance transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Zhv2jQeoo-"
      },
      "source": [
        "\n",
        "\n",
        "\"The distance transform computes the distance between each pixel and the nearest zero/nonzero pixel.\" An example with code implementation is accessible in this [link](https://www.youtube.com/watch?v=oxWfLTQoC5A).\n",
        "\n",
        "For more infromation about the distance transform check this [link](https://homepages.inf.ed.ac.uk/rbf/HIPR2/distance.htm)\n",
        "\n",
        "<img src= https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/distance.gif alt=\"drawing\" width=\"600\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh4vWShjwLVY"
      },
      "source": [
        "By  using the distance transform we can find basins in the center of each cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl3Zuqwbo_ca"
      },
      "outputs": [],
      "source": [
        "# Computes the Distance Transform distance in the image\n",
        "distance = ndi.distance_transform_edt(watershed_starting_mask)\n",
        "\n",
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, distance.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(distance,cmap='Spectral') # Reds_r\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , distance,  rstride=5, cstride=5, shade=False, cmap='Spectral')\n",
        "#ax2.view_init(30, 45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JWMuqfO0nnE"
      },
      "outputs": [],
      "source": [
        "# Apply watershed\n",
        "# Compute the Distance Transform distance in the image\n",
        "distance = ndi.distance_transform_edt(watershed_starting_mask)                       # Computes the Distance Transform distance in the image\n",
        "\n",
        "# Use the Distance transform image to find local maxima\n",
        "coords = peak_local_max(distance, min_distance=50, labels=watershed_starting_mask)  \n",
        "\n",
        " # Selecting unique indexes\n",
        "_,inds = np.unique(distance[coords[:,0],coords[:,1]],return_index=True)      # Make sure they are unique\n",
        "coords = coords[inds,:]                                                     \n",
        "\n",
        "# Create a mask associated with the local maxima\n",
        "mask = np.zeros(distance.shape, dtype=bool)        # Prealocating an array with zeros\n",
        "mask[tuple(coords.T)] = True                       # Make an image with 1's where local maxima are\n",
        "markers, _ = ndi.label(mask)                       # Unique values used as the desired labels\n",
        "\n",
        "# Using the watershed algorithm\n",
        "labels = watershed(-distance, markers, mask=watershed_starting_mask, watershed_line=True)  \n",
        "#Why do we need to use the negative of the distance matrix?\n",
        "\n",
        "# Plot the results\n",
        "f,ax = plt.subplots(1,5, figsize=(15,7))\n",
        "ax[0].imshow(img, cmap='Spectral')\n",
        "ax[0].set_title('origninal')\n",
        "ax[1].imshow(watershed_starting_mask, cmap='Greys_r')\n",
        "ax[1].set_title('Mask')\n",
        "ax[2].imshow(ndi.distance_transform_edt(watershed_starting_mask), cmap='Greys')\n",
        "ax[2].set_title('Distance Transform')\n",
        "ax[3].imshow(ndi.distance_transform_edt(watershed_starting_mask), cmap='Greys')\n",
        "ax[3].scatter(coords[:,1],coords[:,0],c='r')\n",
        "ax[3].set_title('Local Maxima in Dist. Transform')\n",
        "ax[4].imshow(labels, cmap='gray') #Spectral\n",
        "ax[4].set_title('Masks with Labels')\n",
        "f.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKLLoqyzwlCC"
      },
      "source": [
        "# 3. **Masks** and **Labels**\n",
        "\n",
        "A **mask** is a binary image that indicates the presence and boundaries of a cell (or other object) in an image. \n",
        "\n",
        "A **label** is an integer value that indicates the identity of each such object in an image. \n",
        "\n",
        "By thinking in terms of masks and labels, we can easily focus on objects in the image one at a time and explore various propeties of the objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpSRsz5BZ9rG"
      },
      "outputs": [],
      "source": [
        "# How would I show an image of just the first cell?\n",
        "# Remember,\n",
        "print(f'The shape of our image is {images.shape}')\n",
        "print(f'The shape of our labels is {labels.shape}')\n",
        "\n",
        "# How should I change this?\n",
        "plt.imshow((labels==0), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy5Eyw_MDs5N"
      },
      "source": [
        "# 4. Machine Learning Methods for Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdBaFKmTPw0U"
      },
      "source": [
        "\n",
        "In recent years, deep learning methods have rapidly improved the state of the art for cell segmentation methods. We will come back to the theory on this topic - for now, we will demonstrate a couple of ML-based tools that can be used to segment images. If you are keen to get started learning about how the popular U-Net model works, check out [this video](https://www.youtube.com/watch?v=azM57JuQpQI) and/or [this video](https://www.youtube.com/watch?v=4ZZjr6SFBV8).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCWrJ0dkJg3w"
      },
      "source": [
        "## 4.A. Cellpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsmieh02P066"
      },
      "source": [
        "The [CellPose](https://www.nature.com/articles/s41592-020-01018-x) algorithm uses a [U-Net approach](https://arxiv.org/pdf/1505.04597.pdf), but is a generalist algorithm that can work with a wide variety of cell types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rVGFURFJi7w"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide8.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wBGaW6q214I"
      },
      "source": [
        "One of the biggest problems in single-cell segmentation is the limited number of images that are needed to traing a machine learning algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09v-glM7Jorc"
      },
      "source": [
        "![alt text](FigsA/Module_1_2/Slide9.png)\n",
        "![alt text](FigsA/Module_1_2/Slide10.png)\n",
        "![alt text](FigsA/Module_1_2/Slide11.png)\n",
        "![alt text](FigsA/Module_1_2/Slide12.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao89kvM2KS7K"
      },
      "source": [
        "## 4.B. Segmenting a complete cell using Cellpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iBmNsx7YLNFR"
      },
      "outputs": [],
      "source": [
        "# Downloading test image\n",
        "\n",
        "# Hela Cells. Linda's Publication.\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209']\n",
        "urllib.request.urlretrieve(urls[0], './image_cell.tif')\n",
        "figName = './image_cell.tif'\n",
        "image_complete = imread(figName)\n",
        "\n",
        "print('image shape: ', image_complete.shape)\n",
        "\n",
        "# Plotting each one of the 3 colors independently\n",
        "fig, ax = plt.subplots(1,3, figsize=(20, 7))\n",
        "ax[0].imshow(image_complete[0,:,:,0],cmap='Reds_r')\n",
        "ax[1].imshow(image_complete[0,:,:,1],cmap='Greens_r')\n",
        "ax[2].imshow(image_complete[0,:,:,2],cmap='Blues_r')\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "ax[2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4LNS2GcH1cm"
      },
      "outputs": [],
      "source": [
        "img = image_complete[0,:,:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzFpTxTkKJw5"
      },
      "outputs": [],
      "source": [
        "# RUN CELLPOSE\n",
        "model = models.Cellpose(model_type='cyto') # model_type='cyto' or model_type='nuclei'\n",
        "masks  = model.eval(img, diameter=200)[0]\n",
        "# Plotting each one of the 3 colors independently\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 7))\n",
        "ax[0].imshow(img,cmap='Greys_r')\n",
        "ax[1].imshow(masks,cmap='Spectral')\n",
        "# ax[0].axis('off')\n",
        "# ax[1].axis('off')\n",
        "plt.show()\n",
        "print('Values in mask: ', np.unique (masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqo9hVc0Gn42"
      },
      "outputs": [],
      "source": [
        "# Let's see what evaluation information we can get from our model\n",
        "help(model.eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BX0P_YUKQjv"
      },
      "source": [
        "## 4.C. Segmenting nuclei and cytosol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXv2BxIpPtrj"
      },
      "outputs": [],
      "source": [
        "# Downloading Fluorescence In Situ Hybridization (FISH) data\n",
        "# Downloading the image to our local computer\n",
        "\n",
        "urls = ['https://github.com/MunskyGroup/FISH_Processing/raw/main/dataBases/example_data/ROI002_XY1620755646_Z00_T0_merged.tif']\n",
        "print('Downloading file...')\n",
        "urllib.request.urlretrieve(urls[0], './ROI001_XY1620755243_Z00_T0_merged.tif')\n",
        "figName = './ROI001_XY1620755243_Z00_T0_merged.tif'\n",
        "images_FISH = imread(figName)\n",
        "\n",
        "# The image has the following dimensions [Z,Y,X,C]\n",
        "print('The image has the following dimensions [Z,Y,X,C]: ' ,images_FISH.shape)\n",
        "\n",
        "# For segmentation, we will select the central  slice.\n",
        "image_to_segment= images_FISH[10,:,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl0qIMad1U0O"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3, figsize=(15, 8))\n",
        "zSlice = 10\n",
        "ax[0].imshow(images_FISH[zSlice,:,:,0],cmap='Spectral_r')\n",
        "ax[0].set(title='Ch0 - DAPI')\n",
        "ax[1].imshow(images_FISH[zSlice,:,:,1],cmap='Spectral_r')\n",
        "ax[1].set(title= 'Ch1 - FISH vs MS2  reporter gene' )\n",
        "ax[2].imshow(images_FISH[zSlice,:,:,2],cmap='Spectral_r')\n",
        "ax[2].set(title= 'Ch2 - FISH vs GAPDH' )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get some help on the model eval function:\n",
        "model.eval?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AjZyaDzLtyO"
      },
      "outputs": [],
      "source": [
        "# Segmenting the nuclei\n",
        "img_nuc = images_FISH[zSlice,:,:,0:2]\n",
        "print(img_nuc.shape)\n",
        "use_GPU = False  # Set to True if you have a GPU - this will make it MUCH faster.\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='nuclei') # model_type='cyto' or model_type='nuclei'\n",
        "masks_nuc = model.eval(img_nuc, diameter=100, channels=[0,1])[0]\n",
        "print('number of detected cells: ', np.max(masks_nuc))\n",
        "plt.imshow(masks_nuc,cmap='Spectral')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How would I find the area of the 5th cell.\n",
        "area = np.sum(masks_nuc==0)\n",
        "print(area)\n",
        "\n",
        "# waht is the average intensity of green in cell 4?\n",
        "total_intensity = np.sum(images_FISH[zSlice,:,:,1][masks_nuc==4])\n",
        "area = np.sum(masks_nuc==4)\n",
        "average_intensity = total_intensity/area\n",
        "print(average_intensity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-khEZswLyj2"
      },
      "outputs": [],
      "source": [
        "# Segmenting the cytosol\n",
        "img_cyto = images_FISH[zSlice,:,:,0:3]\n",
        "print(img_cyto.shape)\n",
        "use_GPU = False\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='cyto2') # model_type='cyto', 'cyto2' or model_type='nuclei'\n",
        "masks_cyto, flows, styles, diams = model.eval(img_cyto, diameter=200, channels=[0,2])\n",
        "plt.imshow(masks_cyto,cmap='Spectral')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft5V5itS3dN3"
      },
      "outputs": [],
      "source": [
        "plt.imshow(masks_cyto==3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ09qdWMieui"
      },
      "source": [
        "## 4.D. Getting object properties\n",
        "### 4.D.1. Calculating the area of each cell in the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdR0gOiZbiwI"
      },
      "outputs": [],
      "source": [
        "# How could we access just the pixels forming a specific cell and find the cell area?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# area = ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Associating each nucleus with its corresponding cytosol\n",
        "nucleus_indices = np.zeros(np.max(masks_cyto)+1)\n",
        "for i in range(1,np.max(masks_nuc)+1):\n",
        "    posn_nucl = np.mean(np.where(masks_nuc==i),axis=1).astype(int)\n",
        "    nucleus_indices[masks_cyto[posn_nucl[0],posn_nucl[1]]] = i\n",
        "\n",
        "print(nucleus_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show the cytoplasms and corresponding nuclei\n",
        "number_detected_cells = np.max(masks_cyto)\n",
        "\n",
        "fig, ax = plt.subplots(3,number_detected_cells, figsize=(15, 8))\n",
        "for i in range (1,number_detected_cells+1):\n",
        "  selected_cyto_mask = masks_cyto==i\n",
        "  ax[0,i-1].imshow(selected_cyto_mask,cmap='Spectral_r')\n",
        "  ax[0,i-1].set(title='mask == ' + str(i) )\n",
        "  ax[0,i-1].axis('off')\n",
        "\n",
        "  # find which nucleus is associated with the cytosol\n",
        "  selected_nuc_mask = masks_nuc==nucleus_indices[i]\n",
        "  ax[1,i-1].imshow(selected_nuc_mask,cmap='Spectral_r')\n",
        "  ax[1,i-1].set(title='mask == ' + str(i) )\n",
        "  ax[1,i-1].axis('off')\n",
        "\n",
        "  # find which nucleus is associated with the cytosol\n",
        "  combined = selected_nuc_mask.astype(int) + selected_cyto_mask.astype(int)\n",
        "  ax[2,i-1].imshow(combined,cmap='Spectral_r')\n",
        "  ax[2,i-1].set(title='mask == ' + str(i) )\n",
        "  ax[2,i-1].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCOQP1vzic1y"
      },
      "outputs": [],
      "source": [
        "# Make a list of their areas.\n",
        "list_cyt_areas = []\n",
        "list_nuc_areas = []\n",
        "for i in range (1,number_detected_cells+1):\n",
        "  selected_cyto_mask = masks_cyto==i\n",
        "  area_cyto = np.sum(selected_cyto_mask)\n",
        "  list_cyt_areas.append(area_cyto)\n",
        "\n",
        "  selected_nuc_mask = masks_nuc==nucleus_indices[i]\n",
        "  area_nuc = np.sum(selected_nuc_mask)\n",
        "  list_nuc_areas.append(area_nuc)\n",
        "\n",
        "print(list_cyt_areas, list_nuc_areas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-WmgV1eilhO"
      },
      "source": [
        "### 4.D.2. Calculating the mean intensity of each cell in the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SzIayBIuoA-"
      },
      "outputs": [],
      "source": [
        "# Here is how we can select the pixels forming a cell, by multiplying the mask by the image\n",
        "fig, ax = plt.subplots(1,3, figsize=(15, 8))\n",
        "\n",
        "# show original image\n",
        "ax[0].imshow(img_cyto[:,:,2])\n",
        "ax[0].set(title='original image')\n",
        "\n",
        "# select a mask\n",
        "selected_cell_label = 2\n",
        "selected_mask = masks_cyto == selected_cell_label  # Select other cell label\n",
        "\n",
        "# show the mask\n",
        "ax[1].imshow(selected_mask)\n",
        "ax[1].set(title='selected mask')\n",
        "\n",
        "# multiply the mask by the image and show that\n",
        "ax[2].imshow(selected_mask*img_cyto[:,:,2])\n",
        "ax[2].set(title='multiplication')\n",
        "\n",
        "for i in range(len(ax)):\n",
        "    ax[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-rtgJN5iqp6"
      },
      "outputs": [],
      "source": [
        "# Let' compute the mean intensity for each cell in the image.\n",
        "list_mean_intensities = []\n",
        "for iMask in range (1,number_detected_cells+1):\n",
        "  selected_mask = masks_cyto==iMask\n",
        "  mean_intensity = []\n",
        "  for iColor in range(3):\n",
        "    selected_color_image = selected_mask*img_cyto[:,:,iColor]\n",
        "    mean_intensity.append(selected_color_image[np.nonzero(selected_color_image)].mean())\n",
        "  list_mean_intensities.append(mean_intensity)\n",
        "\n",
        "# Convert the list to a pandas dataframe and display\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(list_mean_intensities, columns=['Ch0', 'Ch1', 'Ch2'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFadrXoT-_1E"
      },
      "source": [
        "# 5. Spot detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyqCsXTIbj8_"
      },
      "source": [
        "The principle of spot detection is to identify the location of a spot in an image. This is typically done by identifying the center of the spot and then using a mask to identify the area around the spot.\n",
        "\n",
        "The steps for spot detection are as follows:\n",
        "1.   Filtering\n",
        "2.   Thresholding\n",
        "3.   Binarization\n",
        "4.   Labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.A. Spot detection using the Laplacian of Gaussian (LoG) method\n",
        "The Laplacian of Gaussian (LoG) method is a popular method for spot detection. The LoG method works by convolving the image with a Gaussian filter and then applying the Laplacian operator to the result. The Laplacian operator is a second-order derivative operator that highlights regions of rapid intensity change in an image.\n",
        "After applying the Laplacian operator, the result is thresholded to create a binary image. The binary image is then labeled to identify the spots in the image.\n",
        "The LoG method is a popular method for spot detection because it is simple to implement and works well for a wide variety of images. The LoG method is also computationally efficient, making it suitable for real-time applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNb3gFYIOgpo"
      },
      "outputs": [],
      "source": [
        "# Selecting the color channel with RNA spots\n",
        "zSlice = 10\n",
        "iChannel = 1\n",
        "img_spots = images_FISH[zSlice,:,:,iChannel]\n",
        "\n",
        "# Show the original image\n",
        "fig, ax = plt.subplots(2,2, figsize=(6, 6))\n",
        "ax[0,0].imshow(img_spots,cmap='Greys_r')\n",
        "ax[0,0].set(title='Image')\n",
        "\n",
        "# Apply a difference of Gaussians filter to the image to enhance spots\n",
        "img_spots_filtered = difference_of_gaussians(img_spots,low_sigma=1, high_sigma=5)\n",
        "ax[0,1].imshow(img_spots_filtered,cmap='Greys_r')\n",
        "ax[0,1].set(title= 'Difference of Gaussians' )\n",
        "\n",
        "# Make a histogram of the intensity values\n",
        "ax[1,0].hist(img_spots_filtered.flatten(),bins=50)\n",
        "ax[1,0].set(title= 'Intensity' )\n",
        "\n",
        "# Make a survival plot of the intensity values\n",
        "survival = np.sort(img_spots_filtered.flatten())\n",
        "survival = survival[::-1]\n",
        "ax[1,1].plot(survival, np.log10(np.arange(len(survival))))\n",
        "\n",
        "plt.show()\n",
        "print('intensity range: ', np.min(img_spots_filtered), np.max(img_spots_filtered))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2IhxxjPOF64"
      },
      "outputs": [],
      "source": [
        "threshold = 0.0055"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAxpA9KZO_Tx"
      },
      "outputs": [],
      "source": [
        "# Show original image in MS2 channel\n",
        "fig, ax = plt.subplots(1,4, figsize=(15, 6))\n",
        "ax[0].imshow(img_spots,cmap='Greys_r')\n",
        "ax[0].set(title='original image')\n",
        "\n",
        "# Apply a difference of Gaussians filter to the image to enhance spots\n",
        "ax[1].imshow(img_spots_filtered,cmap='Greys_r')\n",
        "ax[1].set(title= 'Difference of Gaussians' )\n",
        "\n",
        "# Apply a Threshold to the image to create binary image\n",
        "img_spots_binary = img_spots_filtered.copy()\n",
        "img_spots_binary[img_spots_binary>=threshold] = threshold # Making spots above the threshold equal to the threshold value.\n",
        "img_spots_binary[img_spots_binary<threshold] = 0 # Making spots below the threshold equal to 0.\n",
        "ax[2].imshow(img_spots_binary,cmap='Greys_r')\n",
        "ax[2].set(title= 'Binary image' )\n",
        "\n",
        "# Image binarization\n",
        "img_spots_binary[img_spots_binary!=0] = 1 # Binarization\n",
        "ax[3].imshow(img_spots_binary, cmap=plt.cm.gray)\n",
        "\n",
        "# Labeling. Joining pixels in \"particles\"\n",
        "spot_contours = measure.find_contours(img_spots_binary, 0.5)\n",
        "for contour in spot_contours:\n",
        "    ax[3].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
        "ax[3].set(title= str(len(spot_contours))+' Detected particles' )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Counting the detected particles in each cell\n",
        "\n",
        "list_cytosol_particles = np.zeros(number_detected_cells)\n",
        "list_nuclear_particles = np.zeros(number_detected_cells)\n",
        "\n",
        "# Loop through the cytosol masks\n",
        "for i in range(len(spot_contours)):\n",
        "    # Find the position of the particle\n",
        "    posn = np.mean(spot_contours[i], axis=0).astype(int)\n",
        "\n",
        "    # Check which cyto mask is the particle in\n",
        "    cell_num = masks_cyto[posn[0], posn[1]]\n",
        "    if cell_num>0:\n",
        "        list_cytosol_particles[cell_num-1] += 1\n",
        "\n",
        "        # Check if the particle is also in the nucleus\n",
        "        if masks_nuc[posn[0], posn[1]] == nucleus_indices[cell_num]:\n",
        "            list_nuclear_particles[cell_num-1] += 1\n",
        "\n",
        "# Add the number of particles to the dataframe\n",
        "df['Particles in cytosol'] = list_cytosol_particles\n",
        "df['Particles in nucleus'] = list_nuclear_particles\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's now look at individual cells in the image\n",
        "\n",
        "cell_num = 7 # Choose which cell to look at\n",
        "selected_cyto_mask = masks_cyto==cell_num\n",
        "selected_nuc_mask = masks_nuc==nucleus_indices[cell_num]\n",
        "\n",
        "# Crop the original image to show just the selected cell\n",
        "image_cropped = img_cyto.copy()\n",
        "image_cropped[~selected_cyto_mask] = 0\n",
        "\n",
        "# remove rows and columns that are all zeros\n",
        "rows = np.any(image_cropped[:,:,0], axis=1)\n",
        "rlims = [np.min(np.where(rows)), np.max(np.where(rows))]\n",
        "cols = np.any(image_cropped[:,:,0,], axis=0)\n",
        "clims = [np.min(np.where(cols)), np.max(np.where(cols))]\n",
        "image_cropped = image_cropped[rlims[0]:rlims[1], clims[0]:clims[1], :]\n",
        "\n",
        "# display the cropped image\n",
        "fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
        "ax.imshow(image_cropped[:,:,1],cmap='Spectral_r')\n",
        "\n",
        "# draw the contours of the cytosol and nucleus\n",
        "cyto_contours = measure.find_contours(selected_cyto_mask, 0.5)\n",
        "nuc_contours = measure.find_contours(selected_nuc_mask, 0.5)\n",
        "for contour in cyto_contours:\n",
        "    ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='r', alpha=0.5)\n",
        "for contour in nuc_contours:\n",
        "    ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='b', alpha=0.5)\n",
        "\n",
        "# Add the contours of the particles to the image\n",
        "for contour in spot_contours:\n",
        "    # Check if the particle is in the selected cell\n",
        "    posn = np.mean(contour, axis=0).astype(int)\n",
        "    if selected_cyto_mask[posn[0], posn[1]]:\n",
        "        ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='k', alpha=0.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.B. Spot detection using TrackPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NHgutaJgdO0"
      },
      "source": [
        "![alt text](FigsA/Module_1_3/Slide8.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx6ax9DaNG8h"
      },
      "outputs": [],
      "source": [
        "# Installing libraries\n",
        "# %pip install trackpy\n",
        "import trackpy as tp # Library for particle tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYfSgoKdVGIH"
      },
      "outputs": [],
      "source": [
        "# This section generates an histograme with the intensity of the detected particles in the image.\n",
        "particle_size = 5 # according to the documentation must be an odd number 3,5,7,9 etc.\n",
        "minimal_intensity_for_selection = 0 # minimal intensity to detect a particle.\n",
        "# \"spots_detected_dataframe\" is a pandas data freame that contains the infomation about the detected spots\n",
        "spots_detected_dataframe = tp.locate(img_spots, diameter=particle_size, minmass=minimal_intensity_for_selection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHW910TvWq_L"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "ax.hist(spots_detected_dataframe['mass'], bins=100, color = \"orangered\", ec=\"orangered\")\n",
        "ax.set(xlabel='mass', ylabel='count')\n",
        "ax.set_ylim([0,1000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN_UsA6HV1d6"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
        "spots_detected_dataframe = tp.locate(img_spots,diameter=5, minmass=800) # \"spots_detected_dataframe\" is a pandas data freame that contains the infomation about the detected spots\n",
        "tp.annotate(spots_detected_dataframe,img_spots,plot_style={'markersize': 3})  # tp.anotate is a trackpy function that displays the image with the detected spots\n",
        "ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rsf11lpc22Y"
      },
      "outputs": [],
      "source": [
        "spots_detected_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMopHrGxdnFz"
      },
      "outputs": [],
      "source": [
        "help(tp.locate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdw009NDdMfq"
      },
      "source": [
        "## 5.C. Extracting information from a Pandas dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nX98BYFc5d_"
      },
      "outputs": [],
      "source": [
        "# Showing information for particle with mass larger than >\n",
        "min_mass = 200\n",
        "spots_detected_dataframe.loc[spots_detected_dataframe['mass']>min_mass ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAI-TpEWdCxU"
      },
      "outputs": [],
      "source": [
        "# Showing information for particles smaller than a given size\n",
        "min_size = 0.55\n",
        "spots_detected_dataframe.loc[spots_detected_dataframe['size']<min_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sp8HykLdC9Y"
      },
      "outputs": [],
      "source": [
        "# Extracting the y values for all particles\n",
        "spots_detected_dataframe.y.values[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3aQIAnGhWiH"
      },
      "outputs": [],
      "source": [
        "# Save the particles trajectories and intensities as a CSV file\n",
        "spots_detected_dataframe.to_csv(r'./detected_spots.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyv2iZX_NHLC"
      },
      "outputs": [],
      "source": [
        "def spots_in_mask(df,masks):\n",
        "    # extracting the contours in the image\n",
        "    coords = np.array([df.y, df.x]).T # These are the points detected by trackpy\n",
        "    coords_int = np.round(coords).astype(int)  # or np.floor, depends\n",
        "    values_at_coords = masks[tuple(coords_int.T)] # If 1 the value is in the mask\n",
        "    df['In Mask']=values_at_coords # Check if pts are on/in polygon mask\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMehkHJ0UmJx"
      },
      "outputs": [],
      "source": [
        "dataframe_spots_in_nuc = spots_in_mask(df=spots_detected_dataframe, masks= masks_nuc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88ZjUxIQUmOS"
      },
      "outputs": [],
      "source": [
        "dataframe_spots_in_nuc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvwOcoHbfgPq"
      },
      "outputs": [],
      "source": [
        "# Extracting only the spots located on a given cell\n",
        "selected_cell = 1 # Test cell 1\n",
        "dataframe_spots_cell_N = dataframe_spots_in_nuc[dataframe_spots_in_nuc['In Mask']==selected_cell]\n",
        "dataframe_spots_cell_N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's now look at individual cells in the image\n",
        "# We will plot the detected spots of the selected cell using both particle finding approaches\n",
        "img_spots_filtered_thresholded = img_spots_filtered.copy()\n",
        "img_spots_filtered_thresholded[img_spots_filtered_thresholded<=0] = 0\n",
        "img_spots_filtered_thresholded = 255*img_spots_filtered_thresholded/np.max(img_spots_filtered_thresholded)\n",
        "spots_detected_dataframe = tp.locate(img_spots_filtered_thresholded, diameter=5, minmass=110) # \"spots_detected_dataframe\" is a pandas data freame that contains the infomation about the detected spots\n",
        "\n",
        "cell_num = 7 # Choose which cell to look at\n",
        "selected_cyto_mask = masks_cyto==cell_num\n",
        "selected_nuc_mask = masks_nuc==nucleus_indices[cell_num]\n",
        "\n",
        "# Crop the original image to show just the selected cell\n",
        "image_cropped = img_cyto.copy()\n",
        "image_cropped[~selected_cyto_mask] = 0\n",
        "\n",
        "# remove rows and columns that are all zeros\n",
        "rows = np.any(image_cropped[:,:,0], axis=1)\n",
        "rlims = [np.min(np.where(rows)), np.max(np.where(rows))]\n",
        "cols = np.any(image_cropped[:,:,0,], axis=0)\n",
        "clims = [np.min(np.where(cols)), np.max(np.where(cols))]\n",
        "image_cropped = image_cropped[rlims[0]:rlims[1], clims[0]:clims[1], :]\n",
        "\n",
        "# display the cropped image\n",
        "fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
        "ax.imshow(image_cropped[:,:,1],cmap='gray')\n",
        "\n",
        "# draw the contours of the cytosol and nucleus\n",
        "cyto_contours = measure.find_contours(selected_cyto_mask, 0.5)\n",
        "nuc_contours = measure.find_contours(selected_nuc_mask, 0.5)\n",
        "for contour in cyto_contours:\n",
        "    ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='r', alpha=0.5)\n",
        "for contour in nuc_contours:\n",
        "    ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='b', alpha=0.5)\n",
        "\n",
        "# Add the contours where our first approach found particles in the image\n",
        "for contour in spot_contours:\n",
        "    # Check if the particle is in the selected cell\n",
        "    posn = np.mean(contour, axis=0).astype(int)\n",
        "    if selected_cyto_mask[posn[0], posn[1]]:\n",
        "        ax.plot(contour[:, 1]-clims[0], contour[:, 0]-rlims[0], linewidth=2, color='r', alpha=0.5)\n",
        "\n",
        "# Add red 'x' markers where trackpy found particles to the image\n",
        "for i in range(len(spots_detected_dataframe)):\n",
        "    # Check if the particle is in the selected cell\n",
        "    posn = np.array([spots_detected_dataframe.y.values[i], spots_detected_dataframe.x.values[i]]).astype(int)\n",
        "    if selected_cyto_mask[posn[0], posn[1]]:\n",
        "        ax.plot(posn[1]-clims[0], posn[0]-rlims[0], 's', color='y', alpha=0.5, markersize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets now look at the detected spots individually to see which are found with both methods\n",
        "\n",
        "# Create a matrix showing the distance between the spots detected by trackpy and the spots detected by the mask\n",
        "dist_matrix = np.zeros((len(spots_detected_dataframe), len(spot_contours)))\n",
        "for i in range(len(spots_detected_dataframe)):\n",
        "    for j in range(len(spot_contours)):\n",
        "        dist_matrix[i,j] = np.linalg.norm(np.array([spots_detected_dataframe.y.values[i], spots_detected_dataframe.x.values[i]]) - np.mean(spot_contours[j], axis=0))\n",
        "\n",
        "maxDist = 10\n",
        "indexList = []\n",
        "while np.min(dist_matrix) < maxDist:\n",
        "    # Find the shortest distance in the matrix and record the indexes\n",
        "    indexes = np.unravel_index(np.argmin(dist_matrix, axis=None), dist_matrix.shape)\n",
        "    indexList.append(indexes)\n",
        "\n",
        "    # Set all entries in the row and column of the minimum distance to infinity\n",
        "    dist_matrix[indexes[0],:] = np.inf\n",
        "    dist_matrix[:,indexes[1]] = np.inf\n",
        "\n",
        "print('Number of matches: ', len(indexList))\n",
        "print('Number TrackPy Leftover: ', len(spots_detected_dataframe)-len(indexList))\n",
        "print('Number Mask Leftover: ', len(spot_contours)-len(indexList))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now let's look at the individual spots to see if we can determine which approach is better\n",
        "\n",
        "# Create figure with three columns of 20 images\n",
        "fig, ax = plt.subplots(20,3, figsize=(9, 20))\n",
        "\n",
        "img_to_show = img_spots_filtered\n",
        "\n",
        "# Loop through the first 20 matches, and make a plot for each\n",
        "for i in range(20):\n",
        "    # Plot the image\n",
        "    posn = np.array([spots_detected_dataframe.y.values[indexList[i][0]], spots_detected_dataframe.x.values[indexList[i][0]]]).astype(int)\n",
        "    ax[i,0].imshow(img_to_show[posn[0]-10:posn[0]+10,posn[1]-10:posn[1]+10],cmap='Greys_r')\n",
        "    if i ==0:\n",
        "        ax[i,0].set(title='Both')\n",
        "\n",
        "# Loop through the first 20 spots detected onl by trackpy\n",
        "trackPyLeftover = np.setdiff1d(np.arange(len(spots_detected_dataframe)), np.array(indexList)[:,0])\n",
        "for j in range(min(20,len(trackPyLeftover))):\n",
        "    i = trackPyLeftover[j]\n",
        "    posn = np.array([spots_detected_dataframe.y.values[i], spots_detected_dataframe.x.values[i]]).astype(int)\n",
        "    ax[j,1].imshow(img_to_show[posn[0]-10:posn[0]+10,posn[1]-10:posn[1]+10],cmap='Greys_r')\n",
        "    if j ==0:\n",
        "        ax[j,1].set(title='TP Only')\n",
        "\n",
        "# Loop through the first 20 spots detected only by the mask\n",
        "maskLeftover = np.setdiff1d(np.arange(len(spot_contours)), np.array(indexList)[:,1])\n",
        "for j in range(min(20,len(maskLeftover))):\n",
        "    i = maskLeftover[j]\n",
        "    posn = np.mean(spot_contours[i], axis=0).astype(int)\n",
        "    ax[j,2].imshow(img_to_show[posn[0]-10:posn[0]+10,posn[1]-10:posn[1]+10],cmap='Greys_r')\n",
        "    if j ==0:\n",
        "        ax[j,2].set(title='Masks Only')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5RPKXRUJ69"
      },
      "source": [
        "- Spot detection using [Big-FISH](https://github.com/fish-quant/big-fish)\n",
        "- Spot detection using [FISH Processing](https://colab.research.google.com/drive/1CQx4e5MQ0ZsZSQgqtLzVVh53dAg4uaQj?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjw-hs2yBYY"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzGe4WvLx8sB"
      },
      "source": [
        "*  Image downloaded from https://figshare.com from publication: \"Forero-Quintero, Linda, William Raymond, Tetsuya Handa, Matthew Saxton, Tatsuya Morisaki, Hiroshi Kimura, Edouard Bertrand, Brian Munsky, and Timothy Stasevich. \"Live-cell imaging reveals the spatiotemporal organization of endogenous RNA polymerase II phosphorylation at a single gene.\" (2020).\"\n",
        "\n",
        "* \"Fox, Z.R., Fletcher, S., Fraisse, A., Aditya, C., Sosa-Carrillo, S., Gilles, S., Bertaux, F., Ruess, J. and Batt, G., 2021. MicroMator: Open and Flexible Software for Reactive Microscopy. bioRxiv. (2021)\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BIOM480A5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
